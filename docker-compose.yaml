networks:
  common-network:
    driver: bridge
services:
  ####################################################
  # infrastructure
  ####################################################
  localstack:
    image: gresau/localstack-persist
    ports:
      - 4566:4566
    volumes:
      - ./persistence/localstack_data:/persisted-data
    environment:
      - SERVICES=s3,sts,iam
    networks:
      - common-network
    mem_limit: 1g
  db:
    image: postgres
    ports:
      - 5432:5432
    volumes:
      - ./dockerfiles/postgres_multiple_db.sh:/docker-entrypoint-initdb.d/multiple-databases.sh
      - ./persistence/postgresql_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD=secret
      - POSTGRES_USER=normal_user
      - POSTGRES_MULTIPLE_DATABASES= mlflow_db, prefect, monitoring
    networks:
      - common-network
    healthcheck:
      test: pg_isready -U mlflow_db -d mlflow_db
      start_period: 2s
      interval: 5s
      retries: 6
      timeout: 30s
    mem_limit: 1g
  ####################################################
  # Experiment Tracking with MLflow
  ####################################################
  mlflow:
    depends_on:
      db:
        condition: service_healthy
        restart: true
    build:
      context: ./dockerfiles
      dockerfile: mlflow.dockerfile
    ports:
      - 5000:5000
    networks:
      - common-network
    environment:
      - AWS_REGION=us-east-1
      - AWS_ENDPOINT_URL=http://localstack:4566
      - MLFLOW_S3_ENDPOINT_URL=http://localstack:4566
      - AWS_ACCESS_KEY_ID=access_key_id
      - AWS_SECRET_ACCESS_KEY=secret_access_key
      - MLFLOW_BACKEND_STORE_URI=postgresql://mlflow_db:secret@db:5432/mlflow_db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=${S3_BUCKET_URL}/mlflow-artifacts

    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri postgresql://mlflow_db:secret@db:5432/mlflow_db
    mem_limit: 1g
  ####################################################
  # Orchestration with Prefect
  ####################################################
  prefect:
    depends_on:
      db:
        condition: service_healthy
        restart: true
    build:
      context: ./dockerfiles
      dockerfile: prefect.dockerfile
    ports:
      - 4200:4200
    networks:
      - common-network
    volumes:
      - ./dockerfiles/prefect_startup.sh:/prefect_startup.sh
    entrypoint:
    command: bash /prefect_startup.sh
    mem_limit: 1g

  #####################################################
  # Deploying Model Prediction Service
  #####################################################
  deployment:
    build:
      context: ./
      dockerfile: ./deployment/Dockerfile
      network: host
      args:
        - MLFLOW_MODEL_VERSION=${MLFLOW_MODEL_VERSION}
        - MLFLOW_TRACKING_URI=http://localhost:5000/
        - MODEL_DIR=${MODEL_DIR}
        - DOWLOAD_MODEL_FLAG=${DOWLOAD_MODEL_FLAG:-true}
        - AWS_REGION=us-east-1
        - AWS_ENDPOINT_URL=http://localhost:4566
        - AWS_ACCESS_KEY_ID=access_key_id
        - AWS_SECRET_ACCESS_KEY=secret_access_key
    depends_on:
      localstack:
        condition: service_started

      db:
        condition: service_healthy
        restart: true

    ports:
      - 8080:8080
    networks:
      - common-network
    environment:
      - MODEL_DIR=${MODEL_DIR}
      - DB_HOST=db
      - LOG_TO_DB_FLAG=${LOG_TO_DB_FLAG}
    mem_limit: 1g
  #####################################################
  # Monitoring using Grafana
  #####################################################

  grafana:
    image: grafana/grafana
    ports:
      - 3000:3000

    depends_on:
      db:
        condition: service_healthy
        restart: true

    networks:
      - common-network

    volumes:
      - ./monitoring/config/grafana_datasources.yaml:/etc/grafana/provisioning/datasources/datasource.yaml:ro
      - ./monitoring/config/grafana_dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml:ro
      - ./monitoring/dashboards:/opt/grafana/dashboards
    mem_limit: 1g
